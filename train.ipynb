{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Binary Semantic Segmentation on KiTS19 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from source.dataloading import CroppedKiTSDataset\n",
    "from source.models import U_Net\n",
    "from source.transforms import HistogramEqualization, GaussianBlur, SuppressBackground\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train Dataset: 37250\n",
      "Size of Val Dataset: 2933\n",
      "Train loader batches: 6209\n",
      "Val loader batches: 489\n",
      "Image shape: torch.Size([6, 1, 384, 384]), Mask shape: torch.Size([6, 3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    GaussianBlur(kernel_size=5),\n",
    "    HistogramEqualization(),\n",
    "    transforms.ToTensor(),  \n",
    "    SuppressBackground()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_path = r'C:\\Users\\pujau\\OneDrive\\Documents\\thesis\\kits19\\data\\train_data'\n",
    "train_dataset = CroppedKiTSDataset(train_path, transform=transform, crop_size=(384,384))\n",
    "\n",
    "val_path = r'C:\\Users\\pujau\\OneDrive\\Documents\\thesis\\kits19\\data\\val_data'\n",
    "val_dataset = CroppedKiTSDataset(val_path, transform=transform, crop_size=(384,384))  \n",
    "\n",
    "# Check the length of the datasets\n",
    "print(f'Size of Train Dataset: {len(train_dataset)}')\n",
    "print(f'Size of Val Dataset: {len(val_dataset)}')\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=False, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, shuffle=False, pin_memory=True)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "# Check dataloader sizes\n",
    "print(f\"Train loader batches: {len(train_loader)}\")\n",
    "print(f\"Val loader batches: {len(val_loader)}\")\n",
    "\n",
    "# Check a single batch\n",
    "for batch in train_loader:\n",
    "    image, mask = batch\n",
    "    print(f\"Image shape: {image.shape}, Mask shape: {mask.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Background\", \"Kidney\", \"Tumor\"]\n",
    "\n",
    "n = 0 # number of batch want to visualize\n",
    "for i, (images, labels) in enumerate(dataloaders['train']):\n",
    "    if i == n:\n",
    "        images = images\n",
    "        labels = labels\n",
    "        break\n",
    "\n",
    "    batch_size = images.shape[0]\n",
    "    num_channels = labels.shape[1]\n",
    "    \n",
    "    # Number of columns: 1 for image + number of channels for labels\n",
    "    num_cols = num_channels + 1\n",
    "    # Number of rows: based on batch size\n",
    "    num_rows = batch_size\n",
    "\n",
    "    # Create a grid for plotting\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 2 * num_rows))\n",
    "    axes = np.atleast_2d(axes)  \n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # Get the image and label for this batch\n",
    "        image = images[b].squeeze().cpu().numpy()\n",
    "        label = labels[b].cpu().numpy()\n",
    "\n",
    "        # Visualize the input image\n",
    "        ax = axes[b, 0]\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(\"Input Image\")\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Visualize each channel separately for the labels\n",
    "        for c in range(num_channels):\n",
    "            ax = axes[b, c + 1]\n",
    "            # Overlay mask on image\n",
    "            mask = label[c, :, :]\n",
    "            ax.imshow(image, cmap='gray', alpha=0.5)\n",
    "            ax.imshow(mask, cmap='gray', alpha=0.8)  \n",
    "            ax.set_title(f\"{class_names[c] if c < len(class_names) else f'Class {c}'}\")\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "writer = SummaryWriter(log_dir='runs')\n",
    "model = U_Net(img_ch=1, output_ch=3)\n",
    "# model.load_state_dict(torch.load('model_epoch_14_val_loss_0.0173.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 30\n",
    "torch.cuda.empty_cache()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-6)\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()  \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "# Training loop with TensorBoard logging\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs=num_epochs):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets \n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss and progress bar\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'train_loss': running_loss / len(train_loader)})\n",
    "\n",
    "        # Compute the average training loss\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validate the model after each epoch\n",
    "        val_loss = validate_model(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Log losses to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch+1)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch+1)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  \n",
    "            torch.save(model.state_dict(), f'model_epoch_{epoch+1}_val_loss_{val_loss:.4f}.pth')  \n",
    "            print(f\"Model saved at epoch {epoch+1} with val_loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    writer.close() \n",
    "\n",
    "train_model(model, train_loader, val_loader, device=device, num_epochs=num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
